{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eadca4d-31fe-4802-abec-5aac7d928553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FP32 Model...\n",
      "Epoch 1, Loss: 0.2360\n",
      "Epoch 2, Loss: 0.0892\n",
      "Epoch 3, Loss: 0.0728\n",
      "Epoch 4, Loss: 0.0623\n",
      "Epoch 5, Loss: 0.0567\n",
      "\n",
      "Preparing Post-Training Quantization...\n",
      "\n",
      "Quantization-Aware Training...\n",
      "Epoch 1, Loss: 0.0493\n",
      "Epoch 2, Loss: 0.0455\n",
      "Epoch 3, Loss: 0.0411\n",
      "Epoch 4, Loss: 0.0378\n",
      "Epoch 5, Loss: 0.0359\n",
      "\n",
      "=== Comprehensive Model Comparison ===\n",
      "\n",
      "1. Model Sizes:\n",
      "FP32 Model:   216.47 KB\n",
      "PTQ Model:    63.63 KB\n",
      "QAT Model:    63.63 KB\n",
      "\n",
      "2. Inference Times (ms/sample):\n",
      "FP32 Model:   53.00 ms\n",
      "PTQ Model:    25.43 ms\n",
      "QAT Model:    25.58 ms\n",
      "\n",
      "3. Memory Usage:\n",
      "FP32 Model:   0 bytes\n",
      "PTQ Model:    0 bytes\n",
      "QAT Model:    0 bytes\n",
      "\n",
      "4. Overall Accuracy:\n",
      "FP32 Model:   98.77%\n",
      "PTQ Model:    98.73%\n",
      "QAT Model:    98.90%\n",
      "\n",
      "5. Per-Class Accuracy:\n",
      "Digit\tFP32\t\tPTQ\t\tQAT\n",
      "0:\t99.39%\t\t99.49%\t\t99.59%\n",
      "1:\t99.65%\t\t99.56%\t\t99.91%\n",
      "2:\t99.61%\t\t99.61%\t\t99.32%\n",
      "3:\t98.91%\t\t99.01%\t\t98.71%\n",
      "4:\t97.56%\t\t97.96%\t\t99.39%\n",
      "5:\t99.10%\t\t99.10%\t\t98.99%\n",
      "6:\t99.16%\t\t99.16%\t\t97.91%\n",
      "7:\t97.76%\t\t97.57%\t\t98.93%\n",
      "8:\t98.77%\t\t98.56%\t\t98.87%\n",
      "9:\t97.72%\t\t97.22%\t\t97.22%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.quantization\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----- Enhanced CNN model -----\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(8, 16, 3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# ----- Enhanced CNN with Quant/DeQuant stubs -----\n",
    "class QuantEnhancedCNN(EnhancedCNN):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self):\n",
    "        # Store the current mode\n",
    "        was_training = self.training\n",
    "        \n",
    "        # Ensure the model is in eval mode for fusion\n",
    "        self.eval()\n",
    "        \n",
    "        # Fuse conv+bn+relu layers\n",
    "        torch.quantization.fuse_modules(self.conv, [['0', '1', '2'], ['4', '5', '6']], inplace=True)\n",
    "        \n",
    "        # Restore the original training state\n",
    "        if was_training:\n",
    "            self.train()\n",
    "\n",
    "# ----- Data Preparation -----\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ----- Training Function -----\n",
    "def train(model, epochs=5, learning_rate=0.001):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(inputs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(trainloader)\n",
    "        train_losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# ----- Evaluation -----\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    class_correct = [0] * 10\n",
    "    class_total = [0] * 10\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += (predicted[i] == label).item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    # Overall accuracy\n",
    "    overall_accuracy = 100 * correct / total\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    class_accuracies = [100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(10)]\n",
    "    \n",
    "    return overall_accuracy, class_accuracies\n",
    "\n",
    "# ----- Benchmark Inference -----\n",
    "def benchmark(model, dummy_input, n=100):\n",
    "    model.eval()\n",
    "    # Warm-up runs\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            model(dummy_input)\n",
    "    \n",
    "    # Timing\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n):\n",
    "            model(dummy_input)\n",
    "    end = time.time()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_time = (end - start) / n * 1000  # ms/sample\n",
    "    memory_usage = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0\n",
    "    \n",
    "    return avg_time, memory_usage\n",
    "\n",
    "# ----- Visualization Functions -----\n",
    "def plot_comparisons(models, metrics):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plotting function\n",
    "    def subplot(position, data, title, ylabel):\n",
    "        plt.subplot(1, 3, position)\n",
    "        plt.bar(range(len(models)), data)\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Model Type')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xticks(range(len(models)), [m.__class__.__name__ for m in models])\n",
    "    \n",
    "    # Plot metrics\n",
    "    subplot(1, metrics['sizes'], 'Model Size', 'Size (KB)')\n",
    "    subplot(2, metrics['inference_times'], 'Inference Time', 'Time (ms/sample)')\n",
    "    subplot(3, metrics['accuracies'], 'Model Accuracy', 'Accuracy (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('quantization_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "# ----- Detailed Comparison -----\n",
    "def detailed_comparison():\n",
    "    # Initialize models\n",
    "    model_fp32 = EnhancedCNN()\n",
    "    model_ptq = QuantEnhancedCNN()\n",
    "    model_qat = QuantEnhancedCNN()\n",
    "\n",
    "    # 1. Train FP32 Model\n",
    "    print(\"Training FP32 Model...\")\n",
    "    train_losses_fp32 = train(model_fp32)\n",
    "    acc_fp32, class_acc_fp32 = evaluate(model_fp32)\n",
    "    torch.save(model_fp32.state_dict(), \"./model_fp32.pth\")\n",
    "\n",
    "    # 2. Post-Training Quantization (PTQ)\n",
    "    print(\"\\nPreparing Post-Training Quantization...\")\n",
    "    # Load pre-trained weights\n",
    "    model_ptq.load_state_dict(model_fp32.state_dict())\n",
    "    \n",
    "    # Set quantization configuration\n",
    "    model_ptq.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "    \n",
    "    # Fuse model \n",
    "    model_ptq.fuse_model()\n",
    "    \n",
    "    # Prepare for quantization\n",
    "    torch.quantization.prepare(model_ptq, inplace=True)\n",
    "    \n",
    "    # Calibration\n",
    "    for inputs, _ in trainloader:\n",
    "        model_ptq(inputs)\n",
    "        break\n",
    "    \n",
    "    # Convert to quantized model\n",
    "    torch.quantization.convert(model_ptq, inplace=True)\n",
    "    acc_ptq, class_acc_ptq = evaluate(model_ptq)\n",
    "    torch.save(model_ptq.state_dict(), \"./model_ptq.pth\")\n",
    "\n",
    "    # 3. Quantization-Aware Training (QAT)\n",
    "    print(\"\\nQuantization-Aware Training...\")\n",
    "    # Load pre-trained weights\n",
    "    model_qat.load_state_dict(model_fp32.state_dict())\n",
    "    \n",
    "    # Set QAT configuration\n",
    "    model_qat.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "    \n",
    "    # Fuse model\n",
    "    model_qat.fuse_model()\n",
    "    \n",
    "    # Prepare for Quantization-Aware Training\n",
    "    torch.quantization.prepare_qat(model_qat, inplace=True)\n",
    "    \n",
    "    # Train the quantization-aware model\n",
    "    train_losses_qat = train(model_qat, epochs=5)\n",
    "    \n",
    "    # Convert to quantized model\n",
    "    torch.quantization.convert(model_qat, inplace=True)\n",
    "    \n",
    "    # Evaluate\n",
    "    acc_qat, class_acc_qat = evaluate(model_qat)\n",
    "    torch.save(model_qat.state_dict(), \"./model_qat.pth\")\n",
    "\n",
    "    # Benchmark\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)\n",
    "    t_fp32, mem_fp32 = benchmark(model_fp32, dummy_input)\n",
    "    t_ptq, mem_ptq = benchmark(model_ptq, dummy_input)\n",
    "    t_qat, mem_qat = benchmark(model_qat, dummy_input)\n",
    "\n",
    "    # Compute model sizes\n",
    "    size_fp32 = os.path.getsize(\"./model_fp32.pth\") / 1024\n",
    "    size_ptq = os.path.getsize(\"./model_ptq.pth\") / 1024\n",
    "    size_qat = os.path.getsize(\"./model_qat.pth\") / 1024\n",
    "\n",
    "    # Detailed Print Out\n",
    "    print(\"\\n=== Comprehensive Model Comparison ===\")\n",
    "    \n",
    "    print(\"\\n1. Model Sizes:\")\n",
    "    print(f\"FP32 Model:   {size_fp32:.2f} KB\")\n",
    "    print(f\"PTQ Model:    {size_ptq:.2f} KB\")\n",
    "    print(f\"QAT Model:    {size_qat:.2f} KB\")\n",
    "\n",
    "    print(\"\\n2. Inference Times (ms/sample):\")\n",
    "    print(f\"FP32 Model:   {t_fp32:.2f} ms\")\n",
    "    print(f\"PTQ Model:    {t_ptq:.2f} ms\")\n",
    "    print(f\"QAT Model:    {t_qat:.2f} ms\")\n",
    "\n",
    "    print(\"\\n3. Memory Usage:\")\n",
    "    print(f\"FP32 Model:   {mem_fp32} bytes\")\n",
    "    print(f\"PTQ Model:    {mem_ptq} bytes\")\n",
    "    print(f\"QAT Model:    {mem_qat} bytes\")\n",
    "\n",
    "    print(\"\\n4. Overall Accuracy:\")\n",
    "    print(f\"FP32 Model:   {acc_fp32:.2f}%\")\n",
    "    print(f\"PTQ Model:    {acc_ptq:.2f}%\")\n",
    "    print(f\"QAT Model:    {acc_qat:.2f}%\")\n",
    "\n",
    "    print(\"\\n5. Per-Class Accuracy:\")\n",
    "    print(\"Digit\\tFP32\\t\\tPTQ\\t\\tQAT\")\n",
    "    for i in range(10):\n",
    "        print(f\"{i}:\\t{class_acc_fp32[i]:.2f}%\\t\\t{class_acc_ptq[i]:.2f}%\\t\\t{class_acc_qat[i]:.2f}%\")\n",
    "\n",
    "    # Optional: Visualization\n",
    "    metrics = {\n",
    "        'sizes': [size_fp32, size_ptq, size_qat],\n",
    "        'inference_times': [t_fp32, t_ptq, t_qat],\n",
    "        'accuracies': [acc_fp32, acc_ptq, acc_qat]\n",
    "    }\n",
    "    plot_comparisons([model_fp32, model_ptq, model_qat], metrics)\n",
    "\n",
    "# Run the comparison\n",
    "detailed_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f28ecf-8cd1-4d4d-9332-eeef951a3f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
